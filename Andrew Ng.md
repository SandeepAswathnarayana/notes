- Recorded videos for coursera 10 PM to 3 AM  
- Good understanding of the foundations and basics to build a long-term career, try to consistently make decisions based on these principles  
- Coursera motivation: build a website where multiple people could be logged in to the computer at the same time, getting credit (from the computer) for each of our works for anything we do as a group  
- "I'd love to see the owners of mom-and-pop stores with a very little code customize their TV display for their special this week"  
- Why white board and marker?: math, build up a complex concept one piece at a time, enhance understandability  
- Andrew Ng, Peter B, Adam Cole, Morgan Quigley: worked on one of the few pioneering Reinforcement Learning applications (autonomous helicopter)  
- Math Professor (anecdote): "I do what I do because it helps me to discover truth and beauty in the universe"  
- Motivation for Unsupervised Learning: 10^14 synaptic connections in human brain, 10^9 seconds (30 years) life span --> ou nee to learn 10^14 bits in 10^9 seconds (assuming each synaptic connection has a 1-bit parameter). i.e., 10^5 bits per second you need to learn in your life  
- Conviction to pitch an idea at Google Brain (Sebastian Thrun): Adam Cole's graph with the Importance of Scaling the models way bigger than what's possible on the CPUs at Stanford  
- Which of these result in better performance?: Larger Datasets vs Better Architectures. Both (depends on the problem)  
- Landing AI: wrestling with companies (mostly companies outside of consumer internet) having small data  
- The AI funds. Landing AI, deeplearning.ai -- (1) deeplearning.ai: differnecs between various optimization algos, what do you do if the algo overfits, how do you tell if it's overfitting, when and when not to collect more data, learn how to debug ML algos (change the architecture, more data, different optimization algos) (2)


