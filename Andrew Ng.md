- Recorded videos for coursera 10 PM to 3 AM  
- Good understanding of the foundations and basics to build a long-term career, try to consistently make decisions based on these principles  
- Coursera motivation: build a website where multiple people could be logged in to the computer at the same time, getting credit (from the computer) for each of our works for anything we do as a group  
- "I'd love to see the owners of mom-and-pop stores with a very little code customize their TV display for their special this week"  
- Why white board and marker?: math, build up a complex concept one piece at a time, enhance understandability  
- Andrew Ng, Peter B, Adam Cole, Morgan Quigley: worked on one of the few pioneering Reinforcement Learning applications (autonomous helicopter)  
- Math Professor (anecdote): "I do what I do because it helps me to discover truth and beauty in the universe"  
- Motivation for Unsupervised Learning: 10^14 synaptic connections in human brain, 10^9 seconds (30 years) life span --> ou nee to learn 10^14 bits in 10^9 seconds (assuming each synaptic connection has a 1-bit parameter). i.e., 10^5 bits per second you need to learn in your life  
- Conviction to pitch an idea at Google Brain (Sebastian Thrun): Adam Cole's graph with the Importance of Scaling the models way bigger than what's possible on the CPUs at Stanford  
- Which of these result in better performance?: Larger Datasets vs Better Architectures. Both (depends on the problem)  
- Landing AI: wrestling with companies (mostly companies outside of consumer internet) having small data  
- The AI funds. Landing AI, deeplearning.ai
## deeplearning.ai:  
differnecs between various optimization algos, what do you do if the algo overfits, how do you tell if it's overfitting, when and when not to collect more data, learn how to debug ML algos (change the architecture, more data, different optimization algos)  
## Unsupervised Learninig is a beautiful idea. 
"I'd spend more time doing research on Unsupervised Learning."
Generate Infinite labaled data: Examples:  
(1) Self-supervised Learning: (take lots of unlabeled images off the internet, rotate each image by a random multiple of 90 degrees, then train a supervised NN to predict the original orientation -- now you can generate an infinite amounts of labeled data). Conclusion: Taking unlabeled data and making up labeled datasets, training a large NN on these tasks. You can take the hidden layer representations and transfer it to different tasks very powerfully.  
(2) Word Embeddings: Take a sentence, delete a word, the predict the missing word.  
(3) Jigsaw: Cut an image into 3x3 grids, jumble the pieces, then have the NN predict which of the 9! permutations it came from. OpenAI, Facebook, Googel Brain, Deep Mind.  
- Read 2 research papers per week  
- Take handwritten notes  
## Career in Deep Learning:  
- Begin with Coursework, work on projects, read blogs posts or resarch papers, start small with a fun, hobby project which eventually leads to bigger accomplishments  
- Should people get a PhD? Yes. If someone aspires to be a professor. Most pivotal: who are the PEOPLE you are ineracting with in a daily basis. For job search and career advice, consider watching [Andrew Ng on Building a Career in Machine Learning](https://www.youtube.com/watch?v=4kiHsIaK9_w)  
## AI Fund:  
- Startups should be outcome driven and very customer obsessed  
- Motivation: build AI fund to systematically create new startups from scratch, go after this rich space of opportunites in AI to get the projects done.  
Startup Studio: Deals with issues in making ML algos work in real life and get it ot production, how to validate, get the specialized domain knowledge, help with key decisions, provide with the support structure and optimal ecosystem  
## Landing AI:  
- 










